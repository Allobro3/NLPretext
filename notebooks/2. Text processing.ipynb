{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Several tokenizers are available. As you will see bellow, spaCy is much faster than the other implementations (Moses, NLTK) and often return better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nautilus_nlp.preprocessing.tokenizer import tokenize, untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_txt = \"Ceci est un texte français, j'adore 1 !\"\n",
    "eng_txt = \"Let's play together!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ = \"\"\"Les moteurs de recherche tels Google, Exalead ou Yahoo! sont des applications très connues de fouille de textes sur de grandes masses de données. Cependant, les moteurs de recherche ne se basent pas uniquement sur le texte pour l'indexer, mais également sur la façon dont les pages sont mises en valeur les unes par rapport aux autres. L'algorithme utilisé par Google est PageRank, et il est courant de voir HITS dans le milieu académique\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.07 ms, sys: 130 µs, total: 5.2 ms\n",
      "Wall time: 5.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenized_fr_txt = tokenize(str_, lang_module=\"fr_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_fr_txt = tokenize(str_, lang_module=\"fr_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Les', 'moteurs', 'de', 'recherche', 'tels', 'Google', ',', 'Exalead', 'ou', 'Yahoo']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_fr_txt[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### French Moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 s, sys: 6.59 ms, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_fr_txt = tokenize(str_, lang_module=\"fr_moses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Les', 'moteurs', 'de', 'recherche', 'tels', 'Google', ',', 'Exalead', 'ou', 'Yahoo']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_fr_txt[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 990 µs, sys: 0 ns, total: 990 µs\n",
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_eng_txt = tokenize(eng_txt, lang_module=\"en_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_eng_txt = tokenize(eng_txt, lang_module=\"en_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', \"'s\", 'play', 'together', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_eng_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.94 ms, sys: 122 µs, total: 8.06 ms\n",
      "Wall time: 6.95 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_eng_txt = tokenize(eng_txt, lang_module=\"en_nltk\")\n",
    "tokenized_eng_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 35 µs, total: 1.46 s\n",
      "Wall time: 1.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Let's play together!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "untokenize(tokenized_eng_txt,lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 351 µs, total: 3 s\n",
      "Wall time: 3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Les moteurs de recherche tels Google, Exalead ou Yahoo ! sont des applications très connues de fouille de textes sur de grandes masses de données. Cependant, les moteurs de recherche ne se basent pas uniquement sur le texte pour l' indexer, mais également sur la façon dont les pages sont mises en valeur les unes par rapport aux autres. L' algorithme utilisé par Google est PageRank, et il est courant de voir HITS dans le milieu académique\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "untokenize(tokenized_fr_txt,lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilus_nlp.preprocessing.stemming import stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'surviv', 'these', 'dog']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tokens(['I','survived','these', 'dogs'], lang='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je', 'mang', 'dan', 'le', 'cuisin', 'du', 'château']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tokens(['je', 'mangerai', 'dans', 'les', 'cuisines', 'du', 'château'],lang='french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nautilus_nlp.preprocessing.lemmatization import lemmatize_french_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ceci', 'est', 'un', 'texte', 'français', ',', \"j'\", 'adore', 'tes', 'frites', 'bien', 'grasses', 'YOLO', '!']\n"
     ]
    }
   ],
   "source": [
    "txt_to_tokenize=['Ceci', 'est', 'un', 'texte', 'français', ',', \"j'\", 'adore', 'tes', 'frites', 'bien', 'grasses', 'YOLO', '!']\n",
    "print(txt_to_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 ms, sys: 0 ns, total: 17.3 ms\n",
      "Wall time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmatized_tokens = lemmatize_french_tokens(txt_to_tokenize, module='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_tokens = lemmatize_french_tokens(txt_to_tokenize, module='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ceci', 'être', 'un', 'texte', 'français', ',', 'j', \"'\", 'adorer', 'ton', 'frit', 'bien', 'gras', 'yolo', '!']\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nautilus_nlp.preprocessing.lemmatization import lemmatize_english_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_lemmatize = ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 ms, sys: 0 ns, total: 13.7 ms\n",
      "Wall time: 12.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'strip', 'bat', 'be', 'hang', 'on', '-PRON-', 'foot', 'for', 'good']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize_english_tokens(to_lemmatize, module='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 125 ms, total: 1.85 s\n",
      "Wall time: 1.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize_english_tokens(to_lemmatize, module='nltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilus_nlp.preprocessing.preprocess import remove_stopwords\n",
    "from nautilus_nlp.preprocessing.preprocess import get_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRENCH_SW = get_stopwords('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"J'ai un beau cheval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"J'ai\", 'cheval']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(text, FRENCH_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"J'\", 'cheval']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(tokenize(text, lang_module=\"fr_spacy\"),FRENCH_SW)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
