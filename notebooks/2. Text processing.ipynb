{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common text processing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing French and English texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nautilus_nlp.utils.tokenizer import tokenize, untokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_txt = \"Ceci est un texte français, j'adore 1 !\"\n",
    "eng_txt = \"Let's play together!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_ = \"\"\"Les moteurs de recherche tels Google, Exalead ou Yahoo! sont des applications très connues de fouille de textes sur de grandes masses de données. Cependant, les moteurs de recherche ne se basent pas uniquement sur le texte pour l'indexer, mais également sur la façon dont les pages sont mises en valeur les unes par rapport aux autres. L'algorithme utilisé par Google est PageRank, et il est courant de voir HITS dans le milieu académique\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.76 ms, sys: 31 µs, total: 4.79 ms\n",
      "Wall time: 4.42 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Les',\n",
       " 'moteurs',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'tels',\n",
       " 'Google',\n",
       " ',',\n",
       " 'Exalead',\n",
       " 'ou',\n",
       " 'Yahoo',\n",
       " '!',\n",
       " 'sont',\n",
       " 'des',\n",
       " 'applications',\n",
       " 'très',\n",
       " 'connues',\n",
       " 'de',\n",
       " 'fouille',\n",
       " 'de',\n",
       " 'textes',\n",
       " 'sur',\n",
       " 'de',\n",
       " 'grandes',\n",
       " 'masses',\n",
       " 'de',\n",
       " 'données',\n",
       " '.',\n",
       " 'Cependant',\n",
       " ',',\n",
       " 'les',\n",
       " 'moteurs',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'ne',\n",
       " 'se',\n",
       " 'basent',\n",
       " 'pas',\n",
       " 'uniquement',\n",
       " 'sur',\n",
       " 'le',\n",
       " 'texte',\n",
       " 'pour',\n",
       " \"l'\",\n",
       " 'indexer',\n",
       " ',',\n",
       " 'mais',\n",
       " 'également',\n",
       " 'sur',\n",
       " 'la',\n",
       " 'façon',\n",
       " 'dont',\n",
       " 'les',\n",
       " 'pages',\n",
       " 'sont',\n",
       " 'mises',\n",
       " 'en',\n",
       " 'valeur',\n",
       " 'les',\n",
       " 'unes',\n",
       " 'par',\n",
       " 'rapport',\n",
       " 'aux',\n",
       " 'autres',\n",
       " '.',\n",
       " \"L'\",\n",
       " 'algorithme',\n",
       " 'utilisé',\n",
       " 'par',\n",
       " 'Google',\n",
       " 'est',\n",
       " 'PageRank',\n",
       " ',',\n",
       " 'et',\n",
       " 'il',\n",
       " 'est',\n",
       " 'courant',\n",
       " 'de',\n",
       " 'voir',\n",
       " 'HITS',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'milieu',\n",
       " 'académique']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tokenize(str_, lang_module=\"fr_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 ms, sys: 94 µs, total: 6.31 ms\n",
      "Wall time: 4.27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_fr_txt = tokenize(str_, lang_module=\"fr_moses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Les',\n",
       " 'moteurs',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'tels',\n",
       " 'Google',\n",
       " ',',\n",
       " 'Exalead',\n",
       " 'ou',\n",
       " 'Yahoo',\n",
       " '!',\n",
       " 'sont',\n",
       " 'des',\n",
       " 'applications',\n",
       " 'très',\n",
       " 'connues',\n",
       " 'de',\n",
       " 'fouille',\n",
       " 'de',\n",
       " 'textes',\n",
       " 'sur',\n",
       " 'de',\n",
       " 'grandes',\n",
       " 'masses',\n",
       " 'de',\n",
       " 'données',\n",
       " '.',\n",
       " 'Cependant',\n",
       " ',',\n",
       " 'les',\n",
       " 'moteurs',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'ne',\n",
       " 'se',\n",
       " 'basent',\n",
       " 'pas',\n",
       " 'uniquement',\n",
       " 'sur',\n",
       " 'le',\n",
       " 'texte',\n",
       " 'pour',\n",
       " \"l'\",\n",
       " 'indexer',\n",
       " ',',\n",
       " 'mais',\n",
       " 'également',\n",
       " 'sur',\n",
       " 'la',\n",
       " 'façon',\n",
       " 'dont',\n",
       " 'les',\n",
       " 'pages',\n",
       " 'sont',\n",
       " 'mises',\n",
       " 'en',\n",
       " 'valeur',\n",
       " 'les',\n",
       " 'unes',\n",
       " 'par',\n",
       " 'rapport',\n",
       " 'aux',\n",
       " 'autres',\n",
       " '.',\n",
       " \"L'\",\n",
       " 'algorithme',\n",
       " 'utilisé',\n",
       " 'par',\n",
       " 'Google',\n",
       " 'est',\n",
       " 'PageRank',\n",
       " ',',\n",
       " 'et',\n",
       " 'il',\n",
       " 'est',\n",
       " 'courant',\n",
       " 'de',\n",
       " 'voir',\n",
       " 'HITS',\n",
       " 'dans',\n",
       " 'le',\n",
       " 'milieu',\n",
       " 'académique']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(str_, lang_module=\"fr_moses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.3 ms, sys: 3.99 ms, total: 28.3 ms\n",
      "Wall time: 26.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_eng_txt = tokenize(eng_txt, lang_module=\"en_spacy\")\n",
    "tokenized_eng_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.3 ms, sys: 3.71 ms, total: 21 ms\n",
      "Wall time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized_eng_txt = tokenize(eng_txt, lang_module=\"en_nltk\")\n",
    "tokenized_eng_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also untokenize your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's play together!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untokenize(tokenized_eng_txt,lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ceci est un texte français, j' adore !\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here the \"J'adore\" is not handled in the right way\n",
    "untokenize(tokenized_fr_txt,lang='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nautilus_nlp.utils.stemmer import stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'surviv', 'these', 'dog']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tokens(['I','survived','these', 'dogs'], lang='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je', 'mang', 'dan', 'le', 'cuisin', 'du', 'château']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tokens(tokenize(\"je mangerai dans les cuisines du château\"),lang='french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nautilus_nlp.utils.lemmatizer import lemmatize_french_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ceci', 'est', 'un', 'texte', 'français', ',', \"j'\", 'adore', 'tes', 'frites', 'bien', 'grasses', 'YOLO', '!']\n"
     ]
    }
   ],
   "source": [
    "txt_to_tokenize=['Ceci', 'est', 'un', 'texte', 'français', ',', \"j'\", 'adore', 'tes', 'frites', 'bien', 'grasses', 'YOLO', '!']\n",
    "print(txt_to_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.9 ms, sys: 51.9 ms, total: 89.8 ms\n",
      "Wall time: 65.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ceci',\n",
       " 'être',\n",
       " 'un',\n",
       " 'texte',\n",
       " 'français',\n",
       " ',',\n",
       " 'j',\n",
       " \"'\",\n",
       " 'adorer',\n",
       " 't',\n",
       " 'frite',\n",
       " 'bien',\n",
       " 'gras',\n",
       " 'yolo',\n",
       " '!']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize_french_tokens(txt_to_tokenize, module='spacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/hugo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nautilus_nlp.utils.lemmatizer import lemmatize_english_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_lemmatize = ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 ms, sys: 4.4 ms, total: 31.6 ms\n",
      "Wall time: 31.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the', 'strip', 'bat', 'be', 'hang', 'on', '-PRON-', 'foot', 'for', 'good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize_english_tokens(to_lemmatize, module='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 s, sys: 217 ms, total: 3.28 s\n",
      "Wall time: 3.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'strip', 'bat', 'be', 'hang', 'on', 'their', 'foot', 'for', 'best']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lemmatize_english_tokens(to_lemmatize, module='nltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hugo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nautilus_nlp.utils.preprocess import remove_stopwords\n",
    "from nautilus_nlp.utils.tokenizer import tokenize\n",
    "from nautilus_nlp.utils.constants import get_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRENCH_SW = get_stopwords('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"J'ai un beau cheval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"J'ai\", 'beau', 'cheval']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(text, FRENCH_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"J'\", 'beau', 'cheval']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(tokenize(text, lang_module=\"fr_spacy\"),FRENCH_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix bad encoding\n",
    "\n",
    "Sometimes you messed up you encoding saving files, and you don't know how to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nautilus_nlp.utils.preprocess import fix_bad_unicode\n",
    "from nautilus_nlp.utils import file_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_unicode=file_loader.open_textfile('./bad_encoding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Les augmentations de rÃ©munÃ©rations\\nrÃ©nover l'enquÃªte publique pour en faire un vrai outil  d'amÃ©nagement du territoire et de dialogue social\\nLimitations de vitesse et sÃ©curitÃ© routiÃ¨re\\nPour un nouveau contrat citoyen\\nDÃ©velopper les dÃ©marches de budget participatif dans les collectivitÃ©s et associer les citoyens dans la rÃ©alisation des projets\\nproportienelle\\nPour plus de dÃ©mocratie participative\\nTransparence de la vie public\\n18 mois de trop....ca suffit macron\\nEgalitÃ© devant les infractions routiÃ¨res\\nMesures d'urgence pour une dÃ©mocratie rÃ©gÃ©nÃ©rÃ©e\\nSORTIR DU GRAND EST ! REOUR A LA REGION ALSACE\\nPour plus de transparence\\nEcoutez enfin le  peuple.\\nVote obligatoire\\nAvis d'un citoyen ordinaire et socialiste - vive le RIC\\nsuppression du 80 km/h\\nproportionelle et immigration\\nRevoir les plafonds des aides sociales\\nProposition de Refondation du Capitalisme et d'Instauration d'un Dividende Universel FinancÃ©es par l'Ã‰pargne.\\nSuppression du sÃ©nat\\nLimitation de vitesse Ã\\xa0 80km\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_unicode[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Les augmentations de rémunérations\\nrénover l'enquête publique pour en faire un vrai outil  d'aménagement du territoire et de dialogue social\\nLimitations de vitesse et sécurité routière\\nPour un nouveau contrat citoyen\\nDévelopper les démarches de budget participatif dans les collectivités et associer les citoyens dans la réalisation des projets\\nproportienelle\\nPour plus de démocratie participative\\nTransparence de la vie public\\n18 mois de trop....ca suffit macron\\nEgalité devant les infractions routières\\nMesures d'urgence pour une démocratie régénérée\\nSORTIR DU GRAND EST ! REOUR A LA REGION ALSACE\\nPour plus de transparence\\nEcoutez enfin le  peuple.\\nVote obligatoire\\nAvis d'un citoyen ordinaire et socialiste - vive le RIC\\nsuppression du 80 km/h\\nproportionelle et immigration\\nRevoir les plafonds des aides sociales\\nProposition de Refondation du Capitalisme et d'Instauration d'un Dividende Universel Financées par l'Épargne.\\nSuppression du sénat\\nLimitation de vitesse à 80km/h sur les routes départ\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_bad_unicode(bad_unicode)[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
