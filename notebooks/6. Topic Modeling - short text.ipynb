{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling for short text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilus_nlp.models.topic_modeling_short_text import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to use Nautilus functions to clean and preprocess raw text. The ouput of the cleaning process should be a list of sentences (strings). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Cola 1.5L Carrefour',\n",
    " 'Pepsi Cola Light 1.5L',\n",
    " 'Pepsi Cola Twist Light',\n",
    " 'Cola 1.5L CRF DISC',\n",
    " 'Coca-Cola Light 1.5L',\n",
    " 'Coca-Cola Light 4x0.5L',\n",
    " 'Coca-Cola Light 6x0.3L',\n",
    " 'Panzani 200g x 4 bio',\n",
    " 'Rustichella 150g bio',\n",
    " 'De Cecco - Fusilli bio',\n",
    " 'Gerblé sans Gluten50g',\n",
    " 'Penne de riz 100g sans gluten',\n",
    " 'Spaghetti de maïs 50g sans Glute']\n",
    "\n",
    "encoded_text_id, vocab_list, vocab_arr = prepare_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1.5L', 4],\n",
       " ['Coca-Cola', 3],\n",
       " ['Cola', 4],\n",
       " ['Light', 5],\n",
       " ['Pepsi', 2],\n",
       " ['bio', 3],\n",
       " ['de', 2],\n",
       " ['sans', 3]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0], [4, 2, 3, 0], [4, 2, 3], [2, 0], [1, 3, 0], [1, 3], [1, 3], [5], [5], [5], [7], [6, 7], [6, 7]]\n",
      "[[2, 0], [4, 2, 3, 0], [4, 2, 3], [2, 0], [1, 3, 0], [1, 3], [1, 3], [5], [5], [5], [7], [6, 7], [6, 7]]\n",
      "[['1.5L', 4], ['Coca-Cola', 3], ['Cola', 4], ['Light', 5], ['Pepsi', 2], ['bio', 3], ['de', 2], ['sans', 3]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_text_id)\n",
    "print(encoded_text_id)\n",
    "print(vocab_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop begin\n",
      "Step=0, Loss=5.91164999713721, Time=0.0003788471221923828s\n",
      "Step=1, Loss=4.985359112354993, Time=0.0023560523986816406s\n",
      "Step=2, Loss=4.323260756623319, Time=0.0044097900390625s\n",
      "Step=3, Loss=4.021169618891115, Time=0.005792856216430664s\n",
      "Step=4, Loss=3.9201702703506403, Time=0.006429910659790039s\n",
      "loop end\n"
     ]
    }
   ],
   "source": [
    "x = train_nmf_model(encoded_text_id, vocab_list, n_topics= 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get keywords description of the topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 2 : Pmi: 0.22768662780017118 ['1.5L', 'Cola', 'Pepsi', 'Light', 'bio']\n",
      "topic 0 : Pmi: 0.42152248372930645 ['Light', 'Pepsi', 'sans', 'Cola', 'de']\n",
      "topic 1 : Pmi: 0.4373829867469703 ['Coca-Cola', 'Light', '1.5L', 'sans', 'de']\n"
     ]
    }
   ],
   "source": [
    "topics, pmi_score = show_dominant_topic(x, encoded_text_id, vocab_list, n_topKeyword =5)\n",
    "\n",
    "\n",
    "for t in topics.keys():\n",
    "    print('topic', t,': Pmi:', pmi_score[t], topics[t])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign topics to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 1, 3, 2, 2, 2, 3, 3, 3, 1, 1, 1]\n",
      "topic  3 ---> Cola 1.5L Carrefour\n",
      "topic  3 ---> Pepsi Cola Light 1.5L\n",
      "topic  1 ---> Pepsi Cola Twist Light\n",
      "topic  3 ---> Cola 1.5L CRF DISC\n",
      "topic  2 ---> Coca-Cola Light 1.5L\n",
      "topic  2 ---> Coca-Cola Light 4x0.5L\n",
      "topic  2 ---> Coca-Cola Light 6x0.3L\n",
      "topic  3 ---> Panzani 200g x 4 bio\n",
      "topic  3 ---> Rustichella 150g bio\n",
      "topic  3 ---> De Cecco - Fusilli bio\n",
      "topic  1 ---> Gerblé sans Gluten50g\n",
      "topic  1 ---> Penne de riz 100g sans gluten\n",
      "topic  1 ---> Spaghetti de maïs 50g sans Glute\n"
     ]
    }
   ],
   "source": [
    "list_of_topics= get_assigned_topics(x)\n",
    "print(list_of_topics)\n",
    "\n",
    "for i in range(len(list_of_topics)) : \n",
    "    print('topic ', list_of_topics[i],'--->',text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot topics with pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaislaribi/anaconda3/envs/DataScience/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el973044658186304304441590\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el973044658186304304441590_data = {\"mdsDat\": {\"x\": [-0.07207828005578075, -0.27085879991560496, 0.3429370799713856], \"y\": [-0.28854072014416055, 0.19509552731956145, 0.09344519282459897], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [40.10719756781703, 35.155302123790236, 24.73750030839274]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [9.0, 9.0, 10.0, 6.0, 9.0, 9.0, 10.0, 7.0, 10.427871367632429, 8.486483566091643, 7.272729095695264, 1.2006516108182672, 0.41204790158952415, 6.421558091596925e-20, 5.013797446678124e-20, 2.4883131435107527e-20, 9.14037855218546, 9.14037855218546, 8.087967197531219, 4.1120406489053, 2.76558788795799, 1.253310853243789e-18, 3.2243865698780584e-20, 2.5201191342509088e-20, 6.431750080182113, 3.2841126876287086, 1.1974180259819893, 5.98670235584042e-19, 3.97476403756747e-20, 3.103399751032683e-20, 1.6274775761634947e-20, 1.153801355593048e-20], \"Term\": [\"de\", \"sans\", \"bio\", \"Coca-Cola\", \"Pepsi\", \"1.5L\", \"Cola\", \"Light\", \"bio\", \"1.5L\", \"Cola\", \"Pepsi\", \"Light\", \"de\", \"sans\", \"Coca-Cola\", \"sans\", \"de\", \"Pepsi\", \"Light\", \"Cola\", \"bio\", \"Coca-Cola\", \"1.5L\", \"Coca-Cola\", \"Light\", \"1.5L\", \"bio\", \"de\", \"sans\", \"Pepsi\", \"Cola\"], \"Total\": [9.0, 9.0, 10.0, 6.0, 9.0, 9.0, 10.0, 7.0, 10.427871367632429, 9.683901592073632, 10.038316983653253, 9.288618808349486, 7.808201238123532, 9.14037855218546, 9.14037855218546, 6.431750080182113, 9.14037855218546, 9.14037855218546, 9.288618808349486, 7.808201238123532, 10.038316983653253, 10.427871367632429, 6.431750080182113, 9.683901592073632, 6.431750080182113, 7.808201238123532, 9.683901592073632, 10.427871367632429, 9.14037855218546, 9.14037855218546, 9.288618808349486, 10.038316983653253], \"loglift\": [8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.9316, 1.7996, 1.6093, -0.1143, -1.0102, -44.4731, -44.7206, -45.0697, 2.0634, 2.0634, 1.925, 1.4221, 0.7742, -41.5018, -44.6788, -45.3345, 2.4149, 1.5488, 0.3246, -41.8892, -44.4696, -44.717, -45.3786, -45.8002], \"logprob\": [8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0, -0.206, -0.3604, -2.1616, -3.2311, -46.5365, -46.784, -47.4846, 0.0, 0.0, -0.1223, -0.7988, -1.1954, -43.4334, -47.0937, -47.3401, 0.0, -0.6722, -1.6811, -43.8208, -46.533, -46.7805, -47.4259, -47.7699]}, \"token.table\": {\"Topic\": [1, 3, 3, 1, 2, 2, 3, 1, 2, 1, 2, 2], \"Freq\": [0.8261133102124952, 0.1032641637765619, 0.9328720682862902, 0.6973280492535796, 0.2988548782515341, 0.5122818787597335, 0.3842114090698001, 0.10765863263772928, 0.8612690611018342, 0.9589684843101806, 0.984641932346238, 0.984641932346238], \"Term\": [\"1.5L\", \"1.5L\", \"Coca-Cola\", \"Cola\", \"Cola\", \"Light\", \"Light\", \"Pepsi\", \"Pepsi\", \"bio\", \"de\", \"sans\"]}, \"R\": 8, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el973044658186304304441590\", ldavis_el973044658186304304441590_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el973044658186304304441590\", ldavis_el973044658186304304441590_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el973044658186304304441590\", ldavis_el973044658186304304441590_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_pyldavis(x, encoded_text_id, vocab_arr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
