{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_mess_analysed.csv',\n",
    "                 encoding='utf8',\n",
    "                 delimiter=';',\n",
    "                 usecols=['chrn_gaz','stm_clean','offre']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[(df.offre == 'DUAL') | (df.offre == 'GAZ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.stm_clean = df.stm_clean.apply(lambda row: re.findall(\"\\w+\",row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offre</th>\n",
       "      <th>chrn_gaz</th>\n",
       "      <th>stm_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[mettr, jour, adress, palenci, bourg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[souhait, modifi, adress, mail, etre, contacte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[prochain, factur, disponibl, compt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[index, factur, aout, net, superieur, realit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DUAL</td>\n",
       "      <td>0</td>\n",
       "      <td>[savoir, factur, annuel, pai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  offre  chrn_gaz                                          stm_clean\n",
       "0  DUAL         0              [mettr, jour, adress, palenci, bourg]\n",
       "1  DUAL         0  [souhait, modifi, adress, mail, etre, contacte...\n",
       "2  DUAL         0               [prochain, factur, disponibl, compt]\n",
       "3  DUAL         0  [index, factur, aout, net, superieur, realit, ...\n",
       "4  DUAL         0                      [savoir, factur, annuel, pai]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_docs = [' '.join(doc) for doc in df.stm_clean.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mettr jour adress palenci bourg',\n",
       " 'souhait modifi adress mail etre contacte servic cel nadiyaa545 gmail prendr cel compt dorenavent',\n",
       " 'prochain factur disponibl compt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nautilus_nlp.utils.text_vectorizer import Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = Tfidf(max_df=0.95, #ignore terms that have a document frequency strictly higher \n",
    "              min_df=0.01,\n",
    "             max_features=10000,\n",
    "             encoding='utf-8',\n",
    "             #stop_words=SW,\n",
    "             norm=None,\n",
    "             #ngram_range=(1, 2))\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=10000, min_df=0.01,\n",
       "        ngram_range=(1, 1), norm=None, preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uses Sci-kit learn TfidfVectorizer()\n",
    "# You can pass all the arguments supported by sci-kit \n",
    "# Doc : https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "tfidf.tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17744x434 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 300349 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the word count vector matrix.\n",
    "tfidf.compute_tfidf(list_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'euro': 96.099,\n",
       " 'rembours': 116.797,\n",
       " 'adress': 115.531,\n",
       " 'compt': 89.231,\n",
       " 'coupur': 87.871,\n",
       " 'chequ': 82.334,\n",
       " 'mois': 81.935}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get highest-weighted words\n",
    "tfidf.get_top_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mettr', 'adress', 'jour']\n",
      "['cel', 'prendr', 'modifi', 'adress', 'mail', 'servic', 'etre', 'compt', 'souhait']\n",
      "['disponibl', 'prochain', 'compt', 'factur']\n",
      "['index', 'modif', 'modifi', 'lign', 'prochain', 'aout', 'electricit', 'pouv', 'prelev', 'factur']\n",
      "['annuel', 'savoir', 'pai', 'factur']\n",
      "['disponibl', 'ete', 'concern', 'relev', 'compteur', 'demand']\n",
      "['acce', 'juin', 'plait', 'avanc', 'envoi', 'compt', 'mois', 'factur']\n",
      "['conso', 'reel', 'communiqu', 'vient', 'met', 'relev', 'argent', 'conseiller', 'repondu', 'connaitr']\n",
      "['nest', 'point', 'lappliqu', 'effect', 'sup', 'appliqu', 'vrai', 'toujour', 'arriv', 'souc']\n",
      "['mensuel', 'pai', 'prelev']\n"
     ]
    }
   ],
   "source": [
    "# Get highest-weighted words per document\n",
    "for doc in list_of_docs[:10]:\n",
    "    print(tfidf.get_top_tfidf_per_doc(doc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
